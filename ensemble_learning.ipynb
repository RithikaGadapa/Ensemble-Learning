{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Ensemble Learning**"
      ],
      "metadata": {
        "id": "fJcXMTjitjA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q1. What is Ensemble Learning in machine learning? Explain the key idea behind it?**\n",
        "\n",
        "Ensemble Learning is a machine learning technique that combines predictions from multiple models (often called base learners or weak learners) to produce a more accurate and robust final output.\n",
        "\n",
        "The key idea behind ensemble learning is that a group of weak models can work together to outperform any single model by reducing variance, bias, and overfitting. By aggregating the predictions of multiple models—through methods like voting, averaging, or stacking—the ensemble leverages the strengths of each model while compensating for their individual weaknesses."
      ],
      "metadata": {
        "id": "Lks-9EryuIyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q2. What is the difference between Bagging and Boosting?**\n",
        "\n",
        "Bagging and Boosting are two popular ensemble learning methods that differ in how they build and combine models. Bagging, short for Bootstrap Aggregating, aims to reduce variance and prevent overfitting by training multiple models independently on different random subsets of the training data (created using bootstrap sampling). Each model contributes equally to the final prediction through methods like averaging or majority voting. Boosting, on the other hand, focuses on reducing bias by training models sequentially, where each new model tries to correct the errors made by the previous ones. In boosting, more weight is given to data points that were previously misclassified, making the ensemble focus on difficult cases. While bagging improves stability by combining diverse learners, boosting increases accuracy by progressively refining model performance. Examples of bagging include Random Forests, while popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost."
      ],
      "metadata": {
        "id": "W7V-0toluc-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q3.  What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?**\n",
        "\n",
        "Bootstrap sampling is a statistical technique used to create multiple random samples from a single dataset by sampling with replacement. This means that each new dataset (called a bootstrap sample) is formed by randomly selecting observations from the original dataset, and some data points may appear multiple times while others may not appear at all. In the context of Bagging (Bootstrap Aggregating), such as in the Random Forest algorithm, bootstrap sampling is used to train each individual base model (typically decision trees) on a different subset of the data. This process introduces diversity among the models because each one sees a slightly different version of the training set. As a result, when their predictions are combined—through averaging for regression or majority voting for classification—the overall model becomes more stable, less prone to overfitting, and performs better on unseen data. Essentially, bootstrap sampling ensures that the ensemble benefits from variance reduction through the diversity of its component models."
      ],
      "metadata": {
        "id": "f-KdnASEvCgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q4.  What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?**\n",
        "\n",
        "Out-of-Bag (OOB) samples refer to the data points that are not included in a particular bootstrap sample when building an ensemble model such as a Random Forest. Since bootstrap sampling is done with replacement, about one-third of the original dataset is typically left out of each sample. These unused data points are called OOB samples. They play an important role in evaluating the model’s performance without needing a separate validation set. After training each tree in a Random Forest on its bootstrap sample, that tree’s accuracy can be tested on its corresponding OOB samples. The OOB score is then calculated as the average prediction accuracy across all trees using their respective OOB samples. This score provides an unbiased estimate of the model’s generalization performance and helps assess how well the ensemble would perform on unseen data. In summary, the OOB score is a convenient and efficient built-in validation method for ensemble models that use bootstrap sampling."
      ],
      "metadata": {
        "id": "DO7XgJDFvlib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Q5. Compare feature importance analysis in a single Decision Tree vs. a Random Forest.**\n",
        "\n",
        "In a single Decision Tree, feature importance is determined based on how much each feature contributes to reducing impurity or error at the nodes where it is used to split the data. Features that result in greater information gain or larger reductions in Gini impurity (for classification) or mean squared error (for regression) are considered more important. However, the limitation of a single Decision Tree is that it can be unstable and highly sensitive to small changes in the data—meaning its feature importance values can vary significantly if the training data changes slightly.\n",
        "\n",
        "In contrast, a Random Forest calculates feature importance by averaging the importance scores of each feature across all the trees in the ensemble. Since each tree is trained on a different bootstrap sample and uses random subsets of features, the importance values are more stable, reliable, and representative of the overall dataset. This ensemble-based averaging helps reduce bias and variance in the importance scores, providing a more robust measure of which features truly influence the model’s predictions."
      ],
      "metadata": {
        "id": "RGNXWZXxv5kC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6.  Write a Python program to:\n",
        "  -  Load the Breast Cancer dataset using\n",
        "sklearn.datasets.load_breast_cancer()\n",
        " - Train a Random Forest Classifier\n",
        " - Print the top 5 most important features based on feature importance scores."
      ],
      "metadata": {
        "id": "ZdqX796GwHPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.Series(rf.feature_importances_, index=data.feature_names)\n",
        "\n",
        "# Sort and display top 5 important features\n",
        "top_features = feature_importances.sort_values(ascending=False).head(5)\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(top_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGk3thx3wiM3",
        "outputId": "8709bada-5956-4d79-b237-826e4d98812e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "worst area              0.139357\n",
            "worst concave points    0.132225\n",
            "mean concave points     0.107046\n",
            "worst radius            0.082848\n",
            "worst perimeter         0.080850\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. Write a Python program to:\n",
        " - Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        " - Evaluate its accuracy and compare with a single Decision Tree"
      ],
      "metadata": {
        "id": "UuN-yTjfw8pK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGTbAniytgDT",
        "outputId": "b8b9d744-ebde-423a-8ce1-97737e62d44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Single Decision Tree: 1.00\n",
            "Accuracy of Bagging Classifier: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a single Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# ✅ Train a Bagging Classifier using Decision Trees (updated parameter)\n",
        "bagging_clf = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "bag_pred = bagging_clf.predict(X_test)\n",
        "bag_acc = accuracy_score(y_test, bag_pred)\n",
        "\n",
        "# Print and compare accuracies\n",
        "print(\"Accuracy of Single Decision Tree: {:.2f}\".format(dt_acc))\n",
        "print(\"Accuracy of Bagging Classifier: {:.2f}\".format(bag_acc))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8. Write a Python program to:\n",
        " - Train a Random Forest Classifier\n",
        " -  Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        " - Print the best parameters and final accuracy"
      ],
      "metadata": {
        "id": "bY_3HTahyBJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 5, 8, None]\n",
        "}\n",
        "\n",
        "# Use GridSearchCV for hyperparameter tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and parameters\n",
        "best_rf = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred = best_rf.predict(X_test)\n",
        "final_acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Final Accuracy on Test Set: {:.4f}\".format(final_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0kYSG7axaGK",
        "outputId": "bbc442d1-884b-412a-c30e-7ea4be8d55fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 5, 'n_estimators': 150}\n",
            "Final Accuracy on Test Set: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9. Write a Python program to:\n",
        " - Train a Bagging Regressor and a Random Forest Regressor on the California\n",
        "Housing dataset\n",
        " - Compare their Mean Squared Errors (MSE)"
      ],
      "metadata": {
        "id": "RR2hMbysyXX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a Bagging Regressor (base estimator = Decision Tree)\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "bag_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf_reg.fit(X_train, y_train)\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Errors\n",
        "bag_mse = mean_squared_error(y_test, bag_pred)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "# Print comparison\n",
        "print(\"Mean Squared Error (Bagging Regressor): {:.4f}\".format(bag_mse))\n",
        "print(\"Mean Squared Error (Random Forest Regressor): {:.4f}\".format(rf_mse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq772Q2FyK_8",
        "outputId": "c6d6f776-2350-4ad2-bdda-eefbf72fd6df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (Bagging Regressor): 0.2579\n",
            "Mean Squared Error (Random Forest Regressor): 0.2565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q10.  You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data.\n",
        "### You decide to use ensemble techniques to increase model performance.\n",
        "### Explain your step-by-step approach to:\n",
        "### - Choose between Bagging or Boosting\n",
        "### - Handle overfitting\n",
        "###- Select base models\n",
        "### -  Evaluate performance using cross-validation\n",
        "### - Justify how ensemble learning improves decision-making in this real-world context.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Ans:\n",
        "In this scenario, ensemble learning can significantly improve the accuracy and reliability of a loan default prediction model. When choosing between Bagging and Boosting, Boosting techniques such as XGBoost, AdaBoost, or Gradient Boosting are more suitable because they focus on difficult-to-predict instances and reduce both bias and variance. Unlike Bagging, which trains multiple models in parallel and averages their predictions, Boosting works sequentially, where each new model learns from the errors made by the previous ones. Since predicting loan default is a complex classification problem that involves many subtle patterns in customer data, Boosting models are ideal as they can handle non-linear relationships and emphasize improving weak predictions.\n",
        "\n",
        "To handle overfitting in such models, several techniques can be applied. Cross-validation can be used to ensure that the model generalizes well to unseen data, while hyperparameter tuning can help find the optimal values for parameters such as the number of estimators, learning rate, and maximum depth of trees. Regularization techniques available in boosting algorithms, such as limiting tree depth, setting a minimum number of samples per leaf, and using subsampling, can also help control model complexity. Additionally, balancing the dataset using methods like SMOTE or adjusting class weights can ensure that the model does not become biased toward the majority class. Early stopping, where training halts once validation performance stops improving, is another useful method to prevent overfitting.\n",
        "\n",
        "The base model in an ensemble depends on the technique used. For boosting methods, shallow decision trees (also known as decision stumps) are typically used as weak learners because they can capture simple patterns that are later refined through multiple iterations. In contrast, bagging methods like Random Forests usually rely on deeper, independent decision trees. In this problem, a shallow decision tree classifier would serve as the base estimator for the boosting model to ensure that each iteration contributes incremental learning without overfitting the data.\n",
        "\n",
        "Model performance should be evaluated using cross-validation to ensure robustness. The dataset can be split into training and testing sets, and stratified K-fold cross-validation can be applied to maintain class balance across folds. The performance can be assessed using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC, since financial datasets are often imbalanced. In Python, a Gradient Boosting Classifier can be evaluated using cross-validation to measure the mean ROC-AUC score, providing a fair estimate of the model’s ability to distinguish between defaulters and non-defaulters.\n",
        "\n",
        "Ensemble learning enhances decision-making in this real-world financial context by improving both accuracy and reliability. It combines the strengths of multiple weak learners to build a robust predictive model that is less sensitive to noise and outliers. Boosting methods, in particular, can identify complex relationships in customer data, helping detect potential defaults early. Additionally, ensemble models provide insights into feature importance, revealing which factors—such as income level, credit history, and transaction behavior—most influence default risk. As a result, the financial institution can make more informed lending decisions, minimize losses due to defaults, and improve overall risk management."
      ],
      "metadata": {
        "id": "DJxlWgoKy2SR"
      }
    }
  ]
}